import streamlit as st
import pdfplumber
import pandas as pd
import re
import pytesseract
from pdf2image import convert_from_bytes
from io import BytesIO
import json
import numpy as np
from datetime import datetime
from supabase import create_client, Client
from groq import Groq
import openai
from openai import OpenAI, RateLimitError, APIConnectionError

# Configurar Tesseract
pytesseract.pytesseract.tesseract_cmd = r"C:\\Program Files\\Tesseract-OCR\\tesseract.exe"

# Configura√ß√µes de API armazenadas em secrets
GROQ_API_KEY = st.secrets.get("GROQ_API_KEY", "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")

# Conectar ao Supabase
SUPABASE_URL = st.secrets["SUPABASE_URL"]
SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# Instanciar cliente OpenAI com API moderna
client_openai = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# Instanciar cliente Groq
client_groq = Groq(api_key=GROQ_API_KEY)

# Fun√ß√µes auxiliares para embeddings e similaridade
def cosine_similarity(a, b):
    a = np.array(a)
    b = np.array(b)
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

def get_embedding(text):
    response = client_openai.embeddings.create(input=[text], model="text-embedding-ada-002")
    return response.data[0].embedding

def extract_text_from_pdf(file):
    text = ""
    with pdfplumber.open(file) as pdf:
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n"
    if not text.strip():
        file.seek(0)
        images = convert_from_bytes(file.read())
        for img in images:
            text += pytesseract.image_to_string(img)
    return text

def clean_text_for_ia(text):
    lines = text.split("\n")
    ignore_keywords = ["bank", "sorting", "notify", "charges", "advance"]
    return "\n".join([line for line in lines if not any(kw in line.lower() for kw in ignore_keywords)])

def detectar_modelo_pdf(texto):
    """
    Detecta o modelo/fornecedor do PDF baseado em palavras-chave no texto.
    Esta fun√ß√£o √© crucial para identificar o tipo de documento e aplicar
    o contexto espec√≠fico de cada fornecedor via RAG.
    """
    texto_lower = texto.lower()
    
    # Dicion√°rio de fornecedores e suas palavras-chave de identifica√ß√£o
    fornecedores = {
        "PANORAMA": ["panorama produce"],
        "FRUTTITAL": ["fruttital"],
        "DIRBECK": ["dirbeck"],
        "BRATZLER": ["bratzler"],
        "DAYKA": ["dayka hackett"],
        "GOTTMANN": ["gottmann"],
        "EXCELLENT": ["excellent", "fruits"],
        "GLOBAL": ["global fruit point"],
        "INTERNATIONAL": ["international", "fruit"],
        "SUNSHINE": ["sunshine", "export"],
        "FRESHWAY": ["freshway", "logistics"]
    }
    
    # Verificar cada fornecedor
    for fornecedor, keywords in fornecedores.items():
        if any(keyword in texto_lower for keyword in keywords):
            return fornecedor
            
    # Se n√£o encontrar, retorna gen√©rico
    return "GENERIC"

def processar_texto_com_ia(texto, contexto_extra="", modelo_ia="openai", modelo_pdf="GENERIC"):
    """
    Processa o texto utilizando OpenAI ou Groq conforme selecionado.
    Utiliza o contexto recuperado do RAG para melhorar a extra√ß√£o de dados,
    especialmente quando o modelo do PDF j√° √© conhecido.
    
    Args:
        texto: O texto do PDF para processar
        contexto_extra: Contexto adicional do RAG (documentos similares)
        modelo_ia: O modelo de IA a ser usado (openai ou groq)
        modelo_pdf: O modelo/fornecedor do PDF detectado
    """
    # Instru√ß√£o base para extra√ß√£o de dados
    INSTRUCAO_BASE = """
    <INSTRUCAO>
    Voc√™ deve interpretar o conte√∫do dos PDFs de venda de diferentes fornecedores (Accountsale) e retornar os dados estruturados em um formato padronizado para armazenamento em SQL.

    Para cada PDF, extraia:
    - Nome da empresa
    - N√∫mero do cont√™iner
    - Comiss√£o % (se existir)
    - Comiss√£o Valor (se existir)
    - Trucking container (se aplic√°vel)
    - Valor total
    - Net Amount (valor l√≠quido a receber)

    E tamb√©m a lista de produtos vendidos, contendo:
    - tipo (ex: Mango, Grapes Arra, etc.)
    - tamanho (ex: 8, 10kg, calibre, etc.)
    - quantidade
    - pre√ßo unit√°rio
    - pre√ßo total
    - moeda utilizada (USD, EUR, etc.)

    O resultado deve ser em JSON com a estrutura:
    {
      "dados_principais": {
        "Nome da empresa": "",
        "N√∫mero do cont√™iner": "",
        "Comiss√£o %": "",
        "Comiss√£o Valor": "",
        "Trucking container": "",
        "Valor total": "",
        "Net Amount": ""
      },
      "produtos": []
    }

    Ignore se√ß√µes irrelevantes como: Departure, taxas, transporte, comiss√£o, frete, inspe√ß√µes, banco, pagamentos antecipados, EOP, assinatura, IBAN, dados de banco ou rodap√© fiscal.
    </INSTRUCAO>
    """
    
    # Adicionar contexto espec√≠fico do fornecedor
    instrucao_fornecedor = ""
    if modelo_pdf != "GENERIC":
        instrucao_fornecedor = f"""
        <CONTEXTO_FORNECEDOR>
        Este documento √© do fornecedor {modelo_pdf}. 
        
        Dicas espec√≠ficas para este fornecedor:
        """
        
        # Adicionar dicas espec√≠ficas por fornecedor
        if modelo_pdf == "PANORAMA":
            instrucao_fornecedor += """
            - Os n√∫meros de container geralmente est√£o no in√≠cio do documento
            - Os valores de comiss√£o costumam estar em uma linha com 'commission'
            - Os produtos geralmente est√£o em uma tabela com colunas para quantidade, descri√ß√£o e pre√ßo
            """
        elif modelo_pdf == "DIRBECK":
            instrucao_fornecedor += """
            - Procure o n√∫mero do container pr√≥ximo a "Container No."
            - Os valores est√£o geralmente em EUR
            - A comiss√£o √© frequentemente indicada em percentual
            """
        elif modelo_pdf == "BRATZLER":
            instrucao_fornecedor += """
            - O n√∫mero do container √© encontrado perto de "Container No" ou "Container Number"
            - Os produtos s√£o listados com detalhes espec√≠ficos de calibre
            - Verifique valores totais no final do documento, geralmente em USD
            """
        elif modelo_pdf == "DAYKA":
            instrucao_fornecedor += """
            - Procure a se√ß√£o "Account Sales" para os principais detalhes
            - Os produtos s√£o listados com descri√ß√£o detalhada, incluindo variedade e calibre
            - Verifique valores totais e comiss√µes geralmentes ao final do documento
            """
        elif modelo_pdf == "GOTTMANN":
            instrucao_fornecedor += """
            - O formato inclui "Accountsale" no topo do documento
            - Produtos geralmente listados com c√≥digo, descri√ß√£o e valor
            - Comiss√µes geralmente indicadas em percentual e valor
            """
        
        instrucao_fornecedor += """
        </CONTEXTO_FORNECEDOR>
        """
    
    system_message = "Meu nome √© AccountsaleBot. Extraio dados padronizados de diferentes formatos de Accountsale PDFs para armazenamento em SQL. Use a mem√≥ria fornecida se relevante e as dicas espec√≠ficas do fornecedor. N√£o responda nada que n√£o esteja dentro de <INSTRUCAO></INSTRUCAO>"
    content = contexto_extra + instrucao_fornecedor + INSTRUCAO_BASE + texto
    
    try:
        if modelo_ia == "openai":
            response = client_openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": content}
                ],
                temperature=0.5,
                top_p=1
            )
            content_response = response.choices[0].message.content
            
        elif modelo_ia == "groq":
            response = client_groq.chat.completions.create(
                model="meta-llama/llama-4-scout-17b-16e-instruct",
                messages=[
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": content}
                ],
                temperature=0.7
            )
            content_response = response.choices[0].message.content
            
        try:
            return json.loads(content_response)
        except:
            st.warning(f"A resposta da IA n√£o √© um JSON v√°lido. Tentando extrair JSON da resposta...")
            # Tentar extrair apenas o JSON da resposta (caso tenha texto adicional)
            match = re.search(r'{[\s\S]*}', content_response)
            if match:
                try:
                    return json.loads(match.group())
                except:
                    pass
            return {"dados_principais": {}, "produtos": []}
    except Exception as e:
        st.error(f"Erro ao processar com IA ({modelo_ia}): {e}")
        return {"dados_principais": {}, "produtos": []}

# Configura√ß√£o da p√°gina Streamlit
st.set_page_config(page_title="PDF Processor com Groq e OpenAI", layout="wide")
st.title("ü§ñ PDF Processor - Leitor de PDFs com IA")

# Sele√ß√£o do modelo de IA a ser usado
modelo_ia = st.sidebar.radio(
    "Selecione o modelo de IA:",
    ["openai", "groq"],
    captions=["Usar OpenAI (GPT-4o-mini)", "Usar Groq (Llama-4-Scout)"]
)

uploaded_files = st.file_uploader("üìé Envie os arquivos PDF", type="pdf", accept_multiple_files=True)
memoria = supabase.table("memoria_pdf").select("id, texto, resultado_ia, embedding, arquivo, modelo_pdf, modelo_ia, data_processamento").execute()
        
if uploaded_files:
    for uploaded_file in uploaded_files:
        st.subheader(f"üìÑ Arquivo: {uploaded_file.name}")

        texto_pdf = extract_text_from_pdf(uploaded_file)
        texto_pdf_limpo = clean_text_for_ia(texto_pdf)
        modelo = detectar_modelo_pdf(texto_pdf)

        st.markdown(f"**üîç Modelo PDF detectado:** `{modelo}`")
        st.markdown(f"**üîç Modelo IA selecionado:** `{modelo_ia}`")
        
        with st.expander("Ver texto extra√≠do do PDF"):
            st.text(texto_pdf_limpo)

        reprocessar = st.checkbox(f"üîÅ Reprocessar IA para {uploaded_file.name}?", key=uploaded_file.name)

        # Criar embedding para busca de similaridade
        embedding = get_embedding(texto_pdf_limpo)
        
        # Buscar mem√≥rias similares no Supabase
        #memoria = supabase.table("memoria_pdf").select("id, texto, resultado_ia, embedding, arquivo, modelo_pdf, modelo_ia, data_processamento").execute()
        similares = []
        similares_mesmo_fornecedor = []
        
        if memoria.data:
            for item in memoria.data:
                if item["embedding"]:
                    emb_mem = item["embedding"]
                    if isinstance(emb_mem, str):
                        emb_mem = json.loads(emb_mem)
                    sim = cosine_similarity(emb_mem, embedding)
                    
                    # Separar documentos do mesmo fornecedor
                    if item.get("modelo_pdf") == modelo:
                        similares_mesmo_fornecedor.append((sim, item))
                    else:
                        similares.append((sim, item))
            
            # Priorizar documentos do mesmo fornecedor se houver
            if similares_mesmo_fornecedor:
                similares_mesmo_fornecedor.sort(reverse=True, key=lambda x: x[0])
                top_contexto = similares_mesmo_fornecedor[0][1]["resultado_ia"] if similares_mesmo_fornecedor[0][0] > 0.7 else None
                top_similarity = similares_mesmo_fornecedor[0][0]
                top_source = "mesmo_fornecedor"
            elif similares:
                similares.sort(reverse=True, key=lambda x: x[0])
                top_contexto = similares[0][1]["resultado_ia"] if similares[0][0] > 0.8 else None
                top_similarity = similares[0][0]
                top_source = "outro_fornecedor"
            else:
                top_contexto = None
                top_similarity = 0
                top_source = None
        else:
            top_contexto = None
            top_similarity = 0
            top_source = None

        contexto_extra = ""
        if top_contexto:
            st.markdown(f"**üß† Mem√≥ria mais semelhante usada como contexto:**")
            if top_source == "mesmo_fornecedor":
                st.markdown(f"*Similaridade: {top_similarity:.2f} (do mesmo fornecedor)*")
            else:
                st.markdown(f"*Similaridade: {top_similarity:.2f}*")
            st.code(json.dumps(top_contexto, indent=2))
            contexto_extra = f"<MEMORIA_ANTERIOR>\n{json.dumps(top_contexto)}\n</MEMORIA_ANTERIOR>\n"

        # Processar com IA ou usar mem√≥ria
        resultado = processar_texto_com_ia(texto_pdf_limpo, contexto_extra, modelo_ia, modelo) if reprocessar else None

        if not resultado or resultado == {"dados_principais": {}, "produtos": []}:
            st.info("‚ö†Ô∏è Usando resultado mais pr√≥ximo salvo na mem√≥ria.")
            resultado = top_contexto or {"dados_principais": {}, "produtos": []}
        
        # Se reprocessou, salvar no Supabase
        if reprocessar:
            supabase.table("memoria_pdf").insert({
                "arquivo": uploaded_file.name,
                "modelo_pdf": modelo,
                "texto": texto_pdf_limpo,
                "embedding": embedding,
                "resultado_ia": resultado,
                "modelo_ia": modelo_ia
            }).execute()

        # Verificar se os dados est√£o no formato correto para SQL
        dados_padronizados = True
        campos_necessarios = ["Nome da empresa", "N√∫mero do cont√™iner", "Valor total"]
        for campo in campos_necessarios:
            if campo not in resultado["dados_principais"] or not resultado["dados_principais"][campo]:
                dados_padronizados = False
                break
        
        if not dados_padronizados:
            st.warning("‚ö†Ô∏è Alguns campos necess√°rios para o SQL est√£o ausentes ou vazios!")
            
        # Exibir resultados como dataframes
        df_main = pd.DataFrame([resultado["dados_principais"]])
        df_products = pd.DataFrame(resultado.get("produtos", []))

        st.markdown("**üìä Dados principais extra√≠dos:**")
        st.dataframe(df_main, use_container_width=True)

        st.markdown("**üîπ Lista de produtos extra√≠da:**")
        if not df_products.empty:
            st.dataframe(df_products, use_container_width=True)
        else:
            st.info("Nenhum produto encontrado pela IA.")

        # Bot√£o para gerar SQL INSERT
        if st.button("üîÑ Gerar SQL para inser√ß√£o"):
            try:
                # Sanitizar dados para SQL
                empresa = resultado["dados_principais"].get("Nome da empresa", "").replace("'", "''")
                container = resultado["dados_principais"].get("N√∫mero do cont√™iner", "").replace("'", "''")
                comissao_pct = resultado["dados_principais"].get("Comiss√£o %", "0")
                comissao_valor = resultado["dados_principais"].get("Comiss√£o Valor", "0")
                trucking = resultado["dados_principais"].get("Trucking container", "").replace("'", "''")
                valor_total = resultado["dados_principais"].get("Valor total", "0")
                net_amount = resultado["dados_principais"].get("Net Amount", "0")
                
                # Limpar valores
                comissao_pct = re.sub(r'[^0-9.]', '', str(comissao_pct)) or "0"
                comissao_valor = re.sub(r'[^0-9.]', '', str(comissao_valor)) or "0"
                valor_total = re.sub(r'[^0-9.]', '', str(valor_total)) or "0"
                net_amount = re.sub(r'[^0-9.]', '', str(net_amount)) or "0"
                
                # SQL para inser√ß√£o
                sql = f"""-- Inserir ou obter fornecedor
INSERT INTO fornecedores (nome, identificacao) 
VALUES ('{empresa}', '{modelo}')
ON CONFLICT (identificacao) DO NOTHING;

-- Obter ID do fornecedor
WITH fornecedor_id AS (
    SELECT id FROM fornecedores WHERE identificacao = '{modelo}' LIMIT 1
)

-- Inserir container
INSERT INTO containers (
    numero, 
    fornecedor_id, 
    comissao_percentual, 
    comissao_valor, 
    trucking_container, 
    valor_total, 
    net_amount
)
VALUES (
    '{container}',
    (SELECT id FROM fornecedor_id),
    {comissao_pct},
    {comissao_valor},
    '{trucking}',
    {valor_total},
    {net_amount}
)
RETURNING id;
"""
                
                # SQL para produtos
                if not df_products.empty:
                    sql += "\n-- Inserir produtos (execute ap√≥s obter o ID do container)\n"
                    for _, produto in df_products.iterrows():
                        tipo = str(produto.get('tipo', '')).replace("'", "''")
                        tamanho = str(produto.get('tamanho', '')).replace("'", "''")
                        quantidade = re.sub(r'[^0-9]', '', str(produto.get('quantidade', '0'))) or "0"
                        preco_unit = re.sub(r'[^0-9.]', '', str(produto.get('pre√ßo unit√°rio', '0'))) or "0"
                        preco_total = re.sub(r'[^0-9.]', '', str(produto.get('pre√ßo total', '0'))) or "0"
                        
                        sql += f"""INSERT INTO produtos (container_id, tipo, tamanho, quantidade, preco_unitario, preco_total)
VALUES (
    (SELECT id FROM containers WHERE numero = '{container}' ORDER BY data_processamento DESC LIMIT 1),
    '{tipo}',
    '{tamanho}',
    {quantidade},
    {preco_unit},
    {preco_total}
);
"""
                
                st.code(sql, language="sql")
                
                # Bot√£o para download do SQL
                st.download_button(
                    label="üì• Baixar SQL",
                    data=sql,
                    file_name=f"insert_{uploaded_file.name}.sql",
                    mime="text/plain"
                )
                
            except Exception as e:
                st.error(f"Erro ao gerar SQL: {e}")

        # Op√ß√µes de download
        st.download_button(
            label="üìÖ Baixar dados principais (CSV)",
            data=df_main.to_csv(index=False).encode('utf-8'),
            file_name=f"dados_principais_{uploaded_file.name}.csv",
            mime='text/csv'
        )

        if not df_products.empty:
            output_excel = BytesIO()
            with pd.ExcelWriter(output_excel, engine='xlsxwriter') as writer:
                df_products.to_excel(writer, index=False, sheet_name='Produtos')
            output_excel.seek(0)

            st.download_button(
                label="üìÖ Baixar produtos (Excel)",
                data=output_excel,
                file_name=f"produtos_{uploaded_file.name}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

        st.markdown("---")

    # Hist√≥rico de PDFs processados
    
    st.markdown("## üìö Hist√≥rico completo de PDFs processados")
    if memoria.data:
        historico_df = pd.DataFrame([{
            "Arquivo": item["arquivo"],
            "Modelo PDF": item["modelo_pdf"],
            "Modelo IA": item.get("modelo_ia", "openai"),  # Compatibilidade com registros antigos
            "Data": item["data_processamento"]
        } for item in memoria.data])
        st.dataframe(historico_df.sort_values("Data", ascending=False), use_container_width=True)
    else:
        st.info("Nenhum hist√≥rico encontrado no Supabase.")

# Adicionar estat√≠sticas na barra lateral
with st.sidebar:
    st.markdown("## üìä Estat√≠sticas")
    if memoria.data:
        st.metric("Total de PDFs processados", len(memoria.data))
        
        # Estat√≠sticas por modelo de PDF/fornecedor
        modelos_pdf = {}
        for item in memoria.data:
            modelo_pdf = item.get("modelo_pdf", item.get("modelo", "GENERIC"))  # Compatibilidade com registros antigos
            modelos_pdf[modelo_pdf] = modelos_pdf.get(modelo_pdf, 0) + 1
        
        st.markdown("### Fornecedores detectados")
        for modelo_pdf, count in modelos_pdf.items():
            st.text(f"{modelo_pdf}: {count}")
        
        # Estat√≠sticas por modelo de IA
        modelos_ia = {}
        for item in memoria.data:
            modelo_ia = item.get("modelo_ia", "openai")  # Compatibilidade com registros antigos
            modelos_ia[modelo_ia] = modelos_ia.get(modelo_ia, 0) + 1
        
        st.markdown("### Modelos de IA")
        for modelo_ia, count in modelos_ia.items():
            st.text(f"{modelo_ia}: {count}")
    
    # Adicionar op√ß√£o para limpar cache (√∫til para testar novos modelos)
    st.markdown("## ‚öôÔ∏è Configura√ß√µes")
    if st.button("üßπ Limpar Cache RAG"):
        try:
            # N√£o exclui dados, apenas for√ßa reprocessamento
            st.session_state["force_reprocess"] = True
            st.success("Cache limpo! Pr√≥ximos PDFs ser√£o processados do zero.")
        except Exception as e:
            st.error(f"Erro ao limpar cache: {e}")
    
    # Adicionar op√ß√£o para exportar schema SQL
    if st.button("üì¶ Gerar Schema SQL"):
        sql_schema = """
CREATE TABLE fornecedores (
    id SERIAL PRIMARY KEY,
    nome VARCHAR(255) NOT NULL,
    identificacao VARCHAR(50) UNIQUE
);

CREATE TABLE containers (
    id SERIAL PRIMARY KEY,
    numero VARCHAR(50) NOT NULL,
    fornecedor_id INTEGER REFERENCES fornecedores(id),
    data_processamento TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    comissao_percentual DECIMAL(5,2),
    comissao_valor DECIMAL(10,2),
    trucking_container VARCHAR(100),
    valor_total DECIMAL(12,2) NOT NULL,
    net_amount DECIMAL(12,2),
    moeda VARCHAR(3) DEFAULT 'USD'
);

CREATE TABLE produtos (
    id SERIAL PRIMARY KEY,
    container_id INTEGER REFERENCES containers(id),
    tipo VARCHAR(100) NOT NULL,
    tamanho VARCHAR(50),
    quantidade INTEGER NOT NULL,
    preco_unitario DECIMAL(10,2) NOT NULL,
    preco_total DECIMAL(12,2) NOT NULL,
    observacoes TEXT
);

CREATE TABLE memoria_pdfs (
    id SERIAL PRIMARY KEY,
    arquivo VARCHAR(255) NOT NULL,
    modelo_pdf VARCHAR(50) NOT NULL,
    texto TEXT,
    embedding VECTOR(1536),  -- Para PostgreSQL com pgvector
    resultado_ia JSONB NOT NULL,
    modelo_ia VARCHAR(50) NOT NULL,
    data_processamento TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
        """
        st.code(sql_schema, language="sql")
        
        # Bot√£o para download do SQL
        st.download_button(
            label="üì• Baixar Schema SQL",
            data=sql_schema,
            file_name="pdf_processor_schema.sql",
            mime="text/plain"
        )